# WEEK 6 QUIZ

## Q1. (True/False) RNN models are mostly used in the fields of natural language processing and speech recognition.

`True`

## Q2. (True/False) GRUs and LSTM are a way to deal with the vanishing gradient problem encountered by RNNs.
`True`


## Q3. (True/False) GRUs will generally perform about as well as LSTMs with shorter training time, especially for smaller datasets.
`True`
## Q4. (True/False) The main idea of Seq2Seq models is to improve accuracy by keeping necessary information in the hidden state from one sequence to the next.
`True`

## Q5. (True/False) The main parts of a Seq2Seq model are: an encoder, a hidden state, a sequence state, and a decoder.
`False`

## Q6. Select the correct option, in the context of Seq2Seq models:

    The Greedy Search algorithm selects one best candidate as an input sequence for each time step while the Beam Search produces multiple different hypothesis based on conditional probability.
    
## Q7. Which is the gating mechanism for RNNs that include a reset gate and an update gate?

`GRUs`

## Q8. LSTM models are among the most common Deep Learning models used in forecasting. These are other common uses of LSTM models, except:

Speech Recognition


- [ ] Machine Translation


- [ ] Image Captioning


- [x] Generating Images


- [ ] Anomaly Detection


- [ ] Robotic Control
